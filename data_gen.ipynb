{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-30 09:59:52.247186: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-10-30 09:59:52.417500: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from copy import deepcopy\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import math\n",
    "import random\n",
    "import socket\n",
    "\n",
    "import os\n",
    "import optparse\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "\n",
    "from util.get_dataset import get_tr_test_data\n",
    "\n",
    "# Transformer Definition (Dependencies)\n",
    "\n",
    "# Multi-head attention with Q, K, V\n",
    "class multiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, key_dim, num_heads):\n",
    "        super(multiHeadAttention, self).__init__()\n",
    "        self.key_dim = key_dim\n",
    "        self.num_heads = num_heads\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.WqL = []\n",
    "        self.WkL = []\n",
    "        self.WvL = []\n",
    "\n",
    "        for i in range(self.num_heads):\n",
    "            Wq_init = tf.random_normal_initializer()\n",
    "            Wq = tf.Variable(initial_value=Wq_init(shape=(int(input_shape[-1]), self.key_dim), dtype=\"float32\"), trainable=True)\n",
    "            self.WqL.append(Wq)\n",
    "\n",
    "            Wk_init = tf.random_normal_initializer()\n",
    "            Wk = tf.Variable(initial_value=Wk_init(shape=(int(input_shape[-1]), self.key_dim), dtype=\"float32\"), trainable=True)\n",
    "            self.WkL.append(Wk)\n",
    "\n",
    "            Wv_init = tf.random_normal_initializer()\n",
    "            Wv = tf.Variable(initial_value=Wv_init(shape=(int(input_shape[-1]), int(input_shape[-1])), dtype=\"float32\"), trainable=True)\n",
    "            self.WvL.append(Wv)\n",
    "\n",
    "        Wlt_init = init = tf.random_normal_initializer()\n",
    "        self.Wlt = tf.Variable(initial_value=Wlt_init(shape=((self.num_heads * int(input_shape[-1])), int(input_shape[-1])), dtype=\"float32\"), trainable=True)\n",
    "\n",
    "    def call(self, inputs):\n",
    "\n",
    "        # inputs : batch_size x time_steps x dim\n",
    "        x = inputs\n",
    "\n",
    "        # transform for generating Q,K,V : (batch_size * time_steps) x dim\n",
    "        x_tran = tf.reshape(x, [-1])\n",
    "        x_tran = tf.reshape(x_tran, [-1, int(inputs.shape.as_list()[-1])])\n",
    "\n",
    "        a_xL = []\n",
    "\n",
    "        # Generate Query, Key and Value corresponding to each attention head\n",
    "        for i in range(self.num_heads):\n",
    "\n",
    "            # Query : batch_size x time_steps x dq\n",
    "            xq = tf.matmul(x_tran, self.WqL[i])\n",
    "            xq = tf.reshape(xq, [-1, int(inputs.shape.as_list()[-2]), int(xq.shape.as_list()[-1])])\n",
    "\n",
    "            # Key : batch_size x time_steps x dk\n",
    "            xk = tf.matmul(x_tran, self.WkL[i])\n",
    "            xk = tf.reshape(xk, [-1, int(inputs.shape.as_list()[-2]), int(xk.shape.as_list()[-1])])\n",
    "\n",
    "            # Value : batch_size x time_steps x dv\n",
    "            xv = tf.matmul(x_tran, self.WvL[i])\n",
    "            xv = tf.reshape(xv, [-1, int(inputs.shape.as_list()[-2]), int(xv.shape.as_list()[-1])])\n",
    "\n",
    "            # Transposing each key in a batch (xk_t : batch_size x dk x time_steps)\n",
    "            xk_t = tf.transpose(xk, perm=[0, 2, 1])\n",
    "\n",
    "            # Computing scaled dot product self attention of each time step in each training sample (s_a : batch_size x time_steps x time_steps)\n",
    "            s_a = tf.math.multiply(tf.keras.layers.Dot(axes=(1, 2))([xk_t, xq]), (1/self.key_dim))\n",
    "\n",
    "            # Applying Softmax Layer to the self attention weights for proper scaling (sft_s_a : batch_size x time_steps x time_steps)\n",
    "            sft_s_a = tf.keras.layers.Softmax(axis=2)(s_a)\n",
    "\n",
    "            # Computing attention augmented values for each time step and each training sample (a_x : batch_size x time_steps x dim)\n",
    "            a_xL.append(tf.keras.layers.Dot(axes=(1, 2))([xv, sft_s_a]))\n",
    "\n",
    "        # Concatenate and applying linear transform for making dimensions compatible\n",
    "        a_x = tf.concat(a_xL, -1)\n",
    "\n",
    "        # Transform to shape a_x_tran : ((batch_size x time_steps) x (dim x num_heads))\n",
    "        a_x_tran = tf.reshape(a_x, [-1])\n",
    "        a_x_tran = tf.reshape(a_x_tran, [-1, (self.num_heads*int(inputs.shape.as_list()[-1]))])\n",
    "\n",
    "        # Get the dimensions compatible after applying linear transform\n",
    "        a_x_tran = tf.matmul(a_x_tran, self.Wlt)\n",
    "        a_x_tran = tf.reshape(a_x_tran, [-1, int(inputs.shape.as_list()[-2]), int(inputs.shape.as_list()[-1])])\n",
    "\n",
    "        return a_x_tran\n",
    "\n",
    "\n",
    "# Transformer Block implemented as a Layer\n",
    "class TransformerBlock(layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.att = multiHeadAttention(embed_dim, num_heads)\n",
    "        self.ffn = keras.Sequential(\n",
    "            [layers.Dense(ff_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n",
    "        )\n",
    "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = layers.Dropout(rate)\n",
    "        self.dropout2 = layers.Dropout(rate)\n",
    "\n",
    "    def call(self, inputs, training):\n",
    "        attn_output = self.att(inputs)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        return self.layernorm2(out1 + ffn_output)\n",
    "\n",
    "class PositionEmbeddingLayer(layers.Layer):\n",
    "    def __init__(self, sequence_length, output_dim, **kwargs):\n",
    "        super(PositionEmbeddingLayer, self).__init__(**kwargs)\n",
    "        self.position_embedding_layer = layers.Embedding(\n",
    "            input_dim=(sequence_length), output_dim=output_dim\n",
    "        )\n",
    "        self.sequence_length = sequence_length\n",
    "\n",
    "    def call(self, inputs):\n",
    "        position_indices = tf.range(self.sequence_length)  #tf.range(1, self.sequence_length + 1, 1)\n",
    "        embedded_words = inputs\n",
    "        embedded_indices = self.position_embedding_layer(position_indices)\n",
    "        return embedded_words + embedded_indices\n",
    "    \n",
    "\n",
    "# Creating the model\n",
    "# Initializing the transformer model\n",
    "def get_transformer_model(num_features, num_attn_heads, hidden_layer_dim, num_transformer_blocks, time_dim):\n",
    "  transformer_blocks = []\n",
    "\n",
    "  for i in range(num_transformer_blocks):\n",
    "      transformer_blocks.append(TransformerBlock(num_features, num_attn_heads, hidden_layer_dim))\n",
    "\n",
    "  # Model\n",
    "  inputs = layers.Input(shape=(time_dim, num_features,))\n",
    "  x = inputs\n",
    "\n",
    "  # Trainable Embedding\n",
    "  embedding_layer = PositionEmbeddingLayer(50, num_features)\n",
    "  x = embedding_layer(x)\n",
    "\n",
    "  for i in range(num_transformer_blocks):\n",
    "      x = transformer_blocks[i](x)\n",
    "\n",
    "  x = layers.GlobalAveragePooling1D()(x)\n",
    "  x = layers.Dropout(0.2)(x)\n",
    "  x = layers.Dense(32, activation=\"relu\")(x)\n",
    "  x = layers.Dropout(0.2)(x)\n",
    "  outputs = layers.Dense(1)(x)\n",
    "\n",
    "  model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "  optim = keras.optimizers.SGD(learning_rate=0.0001)\n",
    "  model.compile(optimizer=optim, loss='mse', metrics=['mse'])\n",
    "\n",
    "  return model\n",
    "\n",
    "def aggregate_weights(client_weights):\n",
    "    \"\"\"Aggregate the weights from multiple clients by averaging them.\n",
    "    \n",
    "    Args:\n",
    "        client_weights (list): A list of lists containing the weights from each client.\n",
    "    \n",
    "    Returns:\n",
    "        list: A list containing the averaged weights.\n",
    "    \"\"\"\n",
    "    # Stack the weights along a new dimension\n",
    "    stacked_weights = [np.stack([client_weights[j][i] for j in range(len(client_weights))], axis=0).astype(np.float32) for i in range(len(client_weights[0]))]\n",
    "    \n",
    "    # Calculate the average along the new dimension\n",
    "    averaged_weights = [np.average(weight, axis=0) for weight in stacked_weights]\n",
    "    \n",
    "    return averaged_weights\n",
    "\n",
    "keras.utils.get_custom_objects().update({\"PositionEmbeddingLayer\": PositionEmbeddingLayer})\n",
    "keras.utils.get_custom_objects().update({\"TransformerBlock\":TransformerBlock})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "tmp_file = open(\"result/fl_loss_0.01_E_1_B_10.pkl\", \"rb\")\n",
    "coding_data = pickle.load(tmp_file)\n",
    "tmp_file = open(\"result/fl_base_loss_0.01_E_1_B_10.pkl\", \"rb\")\n",
    "base_data = pickle.load(tmp_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "client0_loss = np.concatenate([[tmp_history.history['loss'][-1]] for tmp_history in coding_data[0]])\n",
    "client1_loss = np.concatenate([[tmp_history.history['loss'][-1]] for tmp_history in coding_data[1]])\n",
    "client2_loss = np.concatenate([[tmp_history.history['loss'][-1]] for tmp_history in coding_data[2]])\n",
    "client3_loss = np.concatenate([[tmp_history.history['loss'][-1]] for tmp_history in coding_data[3]])\n",
    "\n",
    "client0_mse = np.concatenate([[tmp_history.history['mse'][-1]] for tmp_history in coding_data[0]])\n",
    "client1_mse = np.concatenate([[tmp_history.history['mse'][-1]] for tmp_history in coding_data[1]])\n",
    "client2_mse = np.concatenate([[tmp_history.history['mse'][-1]] for tmp_history in coding_data[2]])\n",
    "client3_mse = np.concatenate([[tmp_history.history['mse'][-1]] for tmp_history in coding_data[3]])\n",
    "\n",
    "client0_loss_base = np.concatenate([[tmp_history.history['loss'][-1]] for tmp_history in base_data[0]])\n",
    "client1_loss_base = np.concatenate([[tmp_history.history['loss'][-1]] for tmp_history in base_data[1]])\n",
    "client2_loss_base = np.concatenate([[tmp_history.history['loss'][-1]] for tmp_history in base_data[2]])\n",
    "client3_loss_base = np.concatenate([[tmp_history.history['loss'][-1]] for tmp_history in base_data[3]])\n",
    "\n",
    "client0_mse_base = np.concatenate([[tmp_history.history['mse'][-1]] for tmp_history in base_data[0]])\n",
    "client1_mse_base = np.concatenate([[tmp_history.history['mse'][-1]] for tmp_history in base_data[1]])\n",
    "client2_mse_base = np.concatenate([[tmp_history.history['mse'][-1]] for tmp_history in base_data[2]])\n",
    "client3_mse_base = np.concatenate([[tmp_history.history['mse'][-1]] for tmp_history in base_data[3]])\n",
    "\n",
    "client0_val_loss = np.concatenate([[tmp_history.history['val_loss'][-1]] for tmp_history in coding_data[0]])\n",
    "client1_val_loss = np.concatenate([[tmp_history.history['val_loss'][-1]] for tmp_history in coding_data[1]])\n",
    "client2_val_loss = np.concatenate([[tmp_history.history['val_loss'][-1]] for tmp_history in coding_data[2]])\n",
    "client3_val_loss = np.concatenate([[tmp_history.history['val_loss'][-1]] for tmp_history in coding_data[3]])\n",
    "\n",
    "client0_val_mse = np.concatenate([[tmp_history.history['val_mse'][-1]] for tmp_history in coding_data[0]])\n",
    "client1_val_mse = np.concatenate([[tmp_history.history['val_mse'][-1]] for tmp_history in coding_data[1]])\n",
    "client2_val_mse = np.concatenate([[tmp_history.history['val_mse'][-1]] for tmp_history in coding_data[2]])\n",
    "client3_val_mse = np.concatenate([[tmp_history.history['val_mse'][-1]] for tmp_history in coding_data[3]])\n",
    "\n",
    "client0_val_loss_base = np.concatenate([[tmp_history.history['val_loss'][-1]] for tmp_history in base_data[0]])\n",
    "client1_val_loss_base = np.concatenate([[tmp_history.history['val_loss'][-1]] for tmp_history in base_data[1]])\n",
    "client2_val_loss_base = np.concatenate([[tmp_history.history['val_loss'][-1]] for tmp_history in base_data[2]])\n",
    "client3_val_loss_base = np.concatenate([[tmp_history.history['val_loss'][-1]] for tmp_history in base_data[3]])\n",
    "\n",
    "client0_val_mse_base = np.concatenate([[tmp_history.history['val_mse'][-1]] for tmp_history in base_data[0]])\n",
    "client1_val_mse_base = np.concatenate([[tmp_history.history['val_mse'][-1]] for tmp_history in base_data[1]])\n",
    "client2_val_mse_base = np.concatenate([[tmp_history.history['val_mse'][-1]] for tmp_history in base_data[2]])\n",
    "client3_val_mse_base = np.concatenate([[tmp_history.history['val_mse'][-1]] for tmp_history in base_data[3]])\n",
    "\n",
    "coding_loss = np.array([client0_loss,client1_loss,client2_loss,client3_loss])\n",
    "coding_mse = np.array([client0_mse,client1_mse,client2_mse,client3_mse])\n",
    "\n",
    "base_loss = np.array([client0_loss_base,client1_loss_base,client2_loss_base,client3_loss_base])\n",
    "base_mse = np.array([client0_mse_base,client1_mse_base,client2_mse_base,client3_mse_base])\n",
    "\n",
    "coding_val_loss = np.array([client0_val_loss,client1_val_loss,client2_val_loss,client3_val_loss])\n",
    "coding_val_mse = np.array([client0_val_mse,client1_val_mse,client2_val_mse,client3_val_mse])\n",
    "\n",
    "base_val_loss = np.array([client0_val_loss_base,client1_val_loss_base,client2_val_loss_base,client3_val_loss_base])\n",
    "base_val_mse = np.array([client0_val_mse_base,client1_val_mse_base,client2_val_mse_base,client3_val_mse_base])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'coding_loss':coding_loss,\n",
    "    'coding_mse':coding_mse,\n",
    "    'base_loss': base_loss,\n",
    "    'base_mse': base_mse,\n",
    "    'coding_val_loss': coding_val_loss,\n",
    "    'coding_val_mse': coding_val_mse,\n",
    "    'base_val_loss': base_val_loss,\n",
    "    'base_val_mse': base_val_mse\n",
    "}\n",
    "np.savez('figure_data/l1e1b10.npz',**data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wireless",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
